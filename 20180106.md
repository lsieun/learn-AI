09：13 

	Spark SQL
	Spark Streaming
	kafka
	aggregateByKey
	combineByKey

	推荐系统：
		逻辑回归
		协同过滤

09:22

	知识回顾
	搭建集群
	提交任务的两种方式: client / cluster
	RDD宽窄依赖
	
	Spark术语：Application Jobs stages task 
				Master Worker executor
	Stage概念


10:45 

10:53 client和cluster提交方式
	10:57 client方式提交pi SparkSubmit=Driver
	10:59 以cluster方式提交 DriverWarpper

11:14 aggregateBykey CombineByKey


问题：
（1）将Application提交到cluster，随机选择一台Work节点启动Driver进程，随机的方式是什么？
（2）Spark术语中，左侧概念就是Driver进程吧？

关闭轮询

问题：2个备份，哪个执行完，要哪个结果，对吗？

有没有可能造成数据的积压呢？





23：39 ipython

linux printenv查看环境变量 

python lambda

hive 

apache-hive-1.2.1-bin.tar.gz

解压

hive-site.xml

	vi hive-site.xml


hive-env.sh

	cp hive-env.sh.template hive-env.sh
	vi hive-env.sh

	HADOOP_HOME=/usr/local/hadoop

hive/lib

	mysql-connector-java-5.1.35.jar

启动HDFS：
start-dfs.sh
查看HDFS页面

http://192.168.80.131:50070/


hive/bin

	./hive


GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;

CREATE DATABASE `hive_hdh` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 

[Hive启动报错： Found class jline.Terminal, but interface was expected](https://www.cnblogs.com/HarrisonHao/p/6100854.html)

原因：

hadoop目录下存在老版本jline:

/hadoop-2.6.0/share/hadoop/yarn/lib：

-rw-r--r-- 1 root root  87325 Mar 10 18:10 jline-0.9.94.jar

解决：

cp /hive/apache-hive-1.1.0-bin/lib/jline-2.12.jar /hadoop-2.5.2/share/hadoop/yarn/lib


/usr/local/hive/lib/jline-2.12.jar

cd /usr/local/hadoop/share/hadoop/yarn/lib
rm -rf jline-0.9.94.jar 

cp /usr/local/hive/lib/jline-2.12.jar /usr/local/hadoop/share/hadoop/yarn/lib








