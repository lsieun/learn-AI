## 第4章 深层神经网络 ##

这里包含四部分内容：

- （1）设定结构：讲Tensorflow骨架（网络结构）的两个重要因素：“多层”和“非线性”
- （2）损失函数（优化目标）：由Tensorflow的神经网络结构必须要输出一定的预测结果，预测结果和真实结果会存在一定的差异，为了减少预测结果和真实结果的差异，要对模型进行优化，而优化的目标就是损失函数。
- （3）求解过程：有了损失函数，接下来就是通过一些方法对损失函数进行实际的优化；而这“一些方法”是指梯度下降算法和反向传播算法。
- （4）改进之外：对（2）和（3）过程中的一些问题进行处理，例如学习率是对（3）的梯度下降中的学习率的改进，而正则项是对（2）的损失函数的优化。

## 4.1、深度学习与深层神经网络 ##

在实际中，基本上可以认为**深度学习**就是**深层神经网络**的代名词。深度学习有两个非常重要的特性：**多层** 和 **非线性**。

### 4.1.1、线性变换存在的问题（线性模型的局限性） ###

线性模型的最大特点是任意线性模型的组合仍然还是线性模型。只通过线性变换，任意层的全连接神经网络和单层神经网络模型的表达能力没有任何区别，而且它们都是线性模型。然而线性模型能够解决的问题是有限的，这就是线性模型最大的局限性，也就是为什么深度学习要强调非线性。

因为线性模型就能解决线性可分的问题，所以在深度学习的定义中特意强调它的目的是为解决更加复杂的问题。所谓复杂问题，至少是无法通过直线（或者高维空间的平面）划分的。在现实世界中，绝大部分的问题都是无法线性分割的。

常见的神经网络激活函数：ReLu、sigmoid、tanh。

目前TensorFlow提供了7种不同的非线性激活函数，tf.nn.relu、tf.sigmoid和tf.tanh是其中比较常用的几个。当然，TensorFlow也支持使用自己定义的激活函数。

	a = tf.nn.relu(tf.matmul(x, w1) + biases1)
	y = tf.nn.relu(tf.matmul(a, w2) + biases2)


## 4.1.2、如何实现去线性化（激活函数实现去线性化） ##

如果将每一个神经元（也就是神经网络中的节点）的输出通过一个非线性函数，那么整个神经网络的模型也就不再是线性的了。这个非线性函数就是激活函数。

### 4.1.3、多层：深层网络比浅层网络可以解决更多的问题 ###

深度学习的另外一个重要性质：多层变换。

当加入隐藏层之后，异或问题就可以得到很好的解决。

## 4.2、损失函数的定义 ##

在4.1节中介绍了深度学习的一些性质（多层、非线性），通过这些性质可以构造一个更加有效的神经网络（结构）。

本节将具体介绍**如何刻画不同神经网络模型的效果**。**神经网络模型的效果**以及**优化的目标**是通过**损失函数（loss function）**来定义的。

> 神经网络模型的效果 --> 损失函数
> 优化的目标 --> 损失函数

### 4.2.1、经典损失函数 ###

**分类问题**和**回归问题**是监督学习的两大类。这一小节将分别介绍**分类问题**和**回归问题**中使用到的**经典损失函数**。

**分类问题**希望解决的是将不同的样本分到事先定义好的类别中。通过**神经网络解决多分类问题**最常用的方法是设置n个输出节点，其中n为类别的个数。对于每一个样例，神经网络可以得到一个n维数组作为输出结果。数组中的每一个维度（也就是每一个输出节点）对应一个类别。在理想情况下，如果一个样本属于类别k，那么这个类别所对应的输出节点的输出值应该是1，而其他节点的输出都为0。如识别1为例，神经网络模型的输出结果越接近[0,1,0,0,0,0,0,0,0,0]越好。那么如何判断一个输出向量和期望的向量有多接近呢？**交叉熵（cross entropy）**是常用的评判方法之一。**交叉熵**刻画了**两个概率分布之间的距离**，它是分类问题中使用比较广的一种损失函数。

	cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))

## 4.3、神经网络优化算法 ##

本节将更加具体地介绍如何通过**反向传播算法（backpropagation）**和**梯度下降算法（gradient decent）**调节神经网络中参数的取值。

**梯度下降算法**主要用于优化单个参数的取值，而**反向传播算法**给出了一个高效的方式在所有参数上使用**梯度下降算法**，从而使神经网络模型在训练数据上的损失函数尽可能小。反向传播算法是训练神经网络的核心算法，它可以根据定义好的损失函数优化神经网络中参数的取值，从而使神经网络模型在训练数据集上的损失函数达到一个较小值。神经网络模型中参数的优化过程直接决定了模型的质量，是使用神经网络时非常重要的一步。

## 4.4、神经网络进一步优化 ##

4.4.1小节将介绍通过**指数衰减**的方法设置梯度下降算法中的学习率。通过指数衰减的学习率可以让模型在训练的前期快速接近较优解，又可以保证模型在训练后期不会有太大的波动，从而更加接近局部最优。

4.4.2小节将介绍**过拟合**问题。在训练复杂神经网络模型时，**过拟合**是一个非常常见的问题。

4.4.3小节将介绍**滑动平均模型**。滑动平均模型会将每一轮迭代得到的模型综合起来，从而使最终得到的模型更加健壮。

### 4.4.1、学习率的设置 ###

在训练神经网络时，需要设置**学习率（learning rate）**控制参数更新的速度。

Tensorflow提供了一种更加灵活的学习率设置方法：**指数衰减法**。`tf.train.exponential_decay`函数实现了指数衰减学习率。通过这个函数，可以先使用较大的学习率快速得到一个比较优的解，然后随着迭代的继续逐步减少学习率，使得模型在训练后期更加稳定。`exponential_decay`函数会指数级地减少学习率，它实现了以下代码的功能：

	decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps)

一般来说初始学习率、衰减系数和衰减速度都是根据经验设置的。而且损失函数下降的速度和迭代结束之后总损失的大小没有必然的联系。

### 4.4.2、过拟合问题 ###

所谓**过拟合**，指的是当一个模型过为复杂之后，它可以很好地“记忆”每一个**训练数据**中随机噪声的部分而忘记了要去“学习”**训练数据**中通用的趋势。

为了避免过拟合的问题，一个非常常用的方法是正则化（regularization）。正则化的思想，就是在损失函数中加入刻画模型复杂度的指标。

常用的刻画模型复杂度的函数有两种，一种是L1正则化，另一种是L2正则化。无论是哪一种正则化方式，基本的思想都是希望通过限制权重的大小，使得模型不能任意拟合训练数据中的随机噪声。

但这两种正则化的方法也有很大的区别。首先，L1正则化会让参数变得更稀疏，而L2正则化不会。所谓参数变得更稀疏是指会有更多的参数变为0，这样可以达到类似特征提取的功能。之所以L2正则化不会让参数变得稀疏的原因是当参数很小时，这个参数的平方基本上就可以忽略了，于是模型不会进一步将这个参数调整为0。其次，L1正则化的计算公式不可导，而L2正则化公式可导。因为在优化时需要计算损失函数的偏导数，所以对含有L2正则化损失函数的优化要更加简洁。优化带L1正则的损失函数要更加复杂，而且优化的方法也有很多种。在实践中，也可以将L1正则化和L2正则化同时使用。


### 4.4.3、滑动平均模型 ###

这一小节将介绍另外一个可以使模型在**测试数据**上更健壮（）的方法：**滑动平均模型**。

在Tensorflow中提供了`tf.train.ExponentialMovingAverage`来实现滑动平均模型。在初始化ExponentialMovingAverage时，需要提供一个衰减率（decay）。这个衰减率将用于控制模型的更新速度。ExponentialMovingAverage对每一个变量会维护一个影子变量（shadown variable），这个影子变量的初始值就是相应变量的初始值，而每次运行变量更新时，影子变量的值会更新为：

	shadown_variable = decay * shadow_variable + (1-decay) * variable

其中，`shadown_variable`为影子变量，`variable`为待更新的变量，`decay`为衰减率。在实际应用中，`decay`一般会设成非常接近1的数（比如0.999或0.9999）。




## Tensofflow API ##

### tf.clip_by_value ###

通过`tf.clip_by_value`函数可以将一个张量中的数值限制在一个范围内，这样可以避免一些运算错误（比如 log0是无效的）。

示例：

```python
import tensorflow as tf

v = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=tf.float32,shape=(2,3),name="v")
clip_op = tf.clip_by_value(v, clip_value_min=2.5, clip_value_max=4.5, name="clip_op")
print("clip_op = ", clip_op)

with tf.Session() as sess:
    result = clip_op.eval()
    print(result)
```

输出：

	clip_op =  Tensor("clip_op:0", shape=(2, 3), dtype=float32)
	[[ 2.5  2.5  3. ]
	 [ 4.   4.5  4.5]]

### tf.log ###

`tf.log`函数用于对张量中所有元素依次求对数。

示例

```python
import tensorflow as tf

v = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32, shape=(1,3), name="v")
log_value = tf.log(v, name="log_value")
print("v = ", v)
print("log_value = ", log_value)

with tf.Session() as sess:
    result = log_value.eval()
    print(result)
```

输出：

	v =  Tensor("v:0", shape=(1, 3), dtype=float32)
	log_value =  Tensor("log_value:0", shape=(1, 3), dtype=float32)
	[[ 0.          0.69314718  1.09861231]]

### tf.matmul ###

矩阵乘法是使用`tf.matmul`函数来完成；而直接将两个矩阵通过`*`操作相乘，不是矩阵的乘法，而是元素之间直接相乘。

示例：

```python
import tensorflow as tf

v1 = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32, shape=(2,2), name="v1")
v2 = tf.constant([[5.0, 6.0], [7.0, 8.0]], dtype=tf.float32, shape=(2,2), name="v2")

result1 = v1 * v2
result2 = tf.matmul(v1, v2)

with tf.Session() as sess:
    result1_value = result1.eval()
    result2_value = result2.eval()
    print("v1_value = \n", v1.eval())
    print("v2_value = \n", v2.eval())
    print("result1_value = \n", result1_value)
    print("result2_value = \n", result2_value)

```

输出：

	v1_value = 
	 [[ 1.  2.]
	 [ 3.  4.]]
	v2_value = 
	 [[ 5.  6.]
	 [ 7.  8.]]
	result1_value = 
	 [[  5.  12.]
	 [ 21.  32.]]
	result2_value = 
	 [[ 19.  22.]
	 [ 43.  50.]]

### tf.reduce_mean ###

`tf.reduce_mean`函数是求平均值。

示例：

```python
import tensorflow as tf

v = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=tf.float32, shape=(2,3), name="v")
reduce_mean_op = tf.reduce_mean(v)

with tf.Session() as sess:
    result = reduce_mean_op.eval()
    print("result = ", result)
```

输出：

	result =  3.5

### tf.square ###

示例：

```python
import tensorflow as tf

v1 = tf.constant([1.0, 2.0], dtype=tf.float32, shape=(1,2), name="v1")
v2 = tf.constant([3.0, 4.0], dtype=tf.float32, shape=(1,2), name="v2")
square_op = tf.square(v1 - v2)

with tf.Session() as sess:
    result = square_op.eval()
    print("result = ", result)
```

输出：

	result =  [[ 4.  4.]]

### l1_regularizer+l2_regularizer ###

Tensorflow提供了`tf.contrib.layers.l2_regularizer`函数，它可以返回一个函数，这个函数可以计算一个给定参数的L2正则化项的值。类似的，`tf.contrib.layers.l1_regularizer`可以计算L1正则化项的值。

示例：

```python
import tensorflow as tf

weights = tf.constant([[1.0, 2.0], [-3.0, 4.0]], dtype=tf.float32, shape=(2,2), name="weights")
# 输出为 (|1|+|-2|+|-3|+|4|) * 0.5 = 5。其中，0.5为正则化项的权重
l1_op = tf.contrib.layers.l1_regularizer(.5)(weights)
# 输出为 ((1)^{2} + (-2)^{2} + (-3)^{2} + (4)^{2}) / 2 * 0.5 = 7.5。
# Tensorflow会将L2的正则化损失除以2使得求导得到的结果更加简洁。
l2_op = tf.contrib.layers.l2_regularizer(.5)(weights)

with tf.Session() as sess:
    l1_value = l1_op.eval()
    l2_value = l2_op.eval()
    print("l1_value = ", l1_value)
    print("l2_value = ", l2_value)
```

输出：

	l1_value =  5.0
	l2_value =  7.5

### tf.train.ExponentialMovingAverage ###

示例：

```python
import tensorflow as tf

v1 = tf.Variable(0, dtype=tf.float32, name="v1")
step = tf.Variable(0, trainable=False)

ema = tf.train.ExponentialMovingAverage(0.99, step)
maintain_averages_op = ema.apply([v1])

init_op = tf.global_variables_initializer()

with tf.Session() as sess:
    init_op.run()

    print(sess.run([v1, ema.average(v1)]))

    sess.run(tf.assign(v1, 5))
    sess.run(maintain_averages_op)
    print(sess.run([v1, ema.average(v1)]))

    sess.run(tf.assign(step, 10000))
    sess.run(tf.assign(v1, 10))
    sess.run(maintain_averages_op)
    print(sess.run([v1, ema.average(v1)]))

    sess.run(maintain_averages_op)
    print(sess.run([v1, ema.average(v1)]))


```

输出：

	[0.0, 0.0]
	[5.0, 4.5]
	[10.0, 4.5549998]
	[10.0, 4.6094499]

### other api ###

tf.nn.softmax_cross_entropy_with_logits
tf.nn.sparse_softmax_cross_entropy_with_logits
tf.train.AdamOptimizer(0.001).minimize(loss)







## 0401 ##

	import tensorflow as tf 
	
	v = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
	
	with tf.Session() as sess:
		print(tf.clip_by_value(v, 2.5, 4.5).eval())

## 0402 ##

	import tensorflow as tf 
	
	weights = tf.constant([[1.0, 2.0],[-3.0, 4.0]])
	
	with tf.Session() as sess:
		result_L1 = sess.run(tf.contrib.layers.l1_regularizer(.5)(weights))
		result_L2 = sess.run(tf.contrib.layers.l2_regularizer(.5)(weights))
	
		print("result_L1 = ", result_L1)
		print("result_L2 = ", result_L2)






